# Signup settings
ENABLE_SIGNUP=True

# Database settings
DATABASE_URL=postgresql://postgres:postgres@postgres:5432/postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=postgres

# Redis settings
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0
CACHE_URL=redis://redis:6379/0

# Django settings
# SECRET_KEY: Must be set. Generate with:
#   docker compose run --rm backend python -c "from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())"
SECRET_KEY=
ALLOWED_HOSTS=localhost,127.0.0.1
CORS_ALLOWED_ORIGINS=http://localhost,http://127.0.0.1
SECURE_COOKIES=False
USE_S3_STORAGE=False
FRONTEND_URL=http://localhost
AWS_STORAGE_BUCKET_NAME=
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
# AWS_S3_REGION_NAME: For Cloudflare R2, set to "auto". For standard AWS S3, set your real region (e.g. "us-east-1").
AWS_S3_REGION_NAME=
# AWS_S3_ENDPOINT_URL: For Cloudflare R2, set to your R2 endpoint (e.g. https://<account-id>.r2.cloudflarestorage.com). Leave empty for standard AWS S3.
AWS_S3_ENDPOINT_URL=
# AWS_S3_CUSTOM_DOMAIN: For Cloudflare R2 with a custom domain, set it here. Leave empty for standard AWS S3.
AWS_S3_CUSTOM_DOMAIN=

# OpenAI settings
# Required when using OpenAI for embeddings, LLM, or Whisper
OPENAI_API_KEY=

# Ollama settings
# Used when EMBEDDING_PROVIDER=ollama or LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://host.docker.internal:11434

# Embedding settings
# EMBEDDING_PROVIDER: "openai" (default) or "ollama" (local Ollama server)
EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL: Model name for the selected provider
# - For OpenAI: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
# - For Ollama: qwen3-embedding:0.6b, nomic-embed-text, mxbai-embed-large
EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_VECTOR_SIZE must match the selected EMBEDDING_MODEL:
# text-embedding-3-small=1536, text-embedding-3-large=3072, text-embedding-ada-002=1536
# nomic-embed-text=768, mxbai-embed-large=1024, qwen3-embedding:0.6b=1024
EMBEDDING_VECTOR_SIZE=1536

# PGVector settings
# PGVECTOR_COLLECTION_NAME: Table name used by PGVectorStore for vector storage
PGVECTOR_COLLECTION_NAME=videoq_scenes

# LLM settings (for chat functionality)
# LLM_PROVIDER: "openai" (default) or "ollama" (local Ollama server)
LLM_PROVIDER=openai
# LLM_MODEL: Model name for the selected provider
# - For OpenAI: gpt-4o-mini, gpt-4o, gpt-4-turbo, gpt-3.5-turbo
# - For Ollama: qwen3:0.6b, llama3:8b, mistral:7b
LLM_MODEL=gpt-4o-mini

# Whisper backend settings
# WHISPER_BACKEND: "openai" (default) or "whisper.cpp" (local whisper.cpp server)
WHISPER_BACKEND=openai
WHISPER_LOCAL_URL=http://host.docker.internal:8080